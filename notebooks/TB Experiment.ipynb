{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.609479Z",
     "start_time": "2021-03-10T14:58:02.907483Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from aggregated_models.myimports  import *\n",
    "# import aggregated_models.myJupyterUtils as myJupyterUtils ## Remove stacktraces on Keyboardinterupt\n",
    "plt.style.use('ggplot')\n",
    "import getpass\n",
    "\n",
    "# helpers to compute metrics\n",
    "from aggregated_models.validation import SparkMetricsComputer\n",
    "\n",
    "# baselines\n",
    "\n",
    "# loading public \"criteo attribution dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.630044Z",
     "start_time": "2021-03-10T14:58:04.610705Z"
    }
   },
   "outputs": [],
   "source": [
    "# code to prepare the aggregated dataset\n",
    "from aggregated_models.aggdataset import AggDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.646507Z",
     "start_time": "2021-03-10T14:58:04.631250Z"
    }
   },
   "outputs": [],
   "source": [
    "## Most relevant code is there:\n",
    "from aggregated_models.agg_mrf_model import AggMRFModel, AggMRFModelParams\n",
    "# also in https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/baseaggmodel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thx.hadoop.spark_config_builder import create_remote_spark_session\n",
    "from thx.datasources.parquet import create_df_from_parquet\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = create_remote_spark_session('Test Spark parallelize', 200, 8, memory='4g', memoryOverhead='2g', driver_memory='12g', hadoop_file_systems=['viewfs://root', 'viewfs://prod-am6'])\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "3 versions of the dataset are used for experiments: \"small\" , \"sampled\" and \"full\"\n",
    "- \"full\" has 11 features with about 16M samples\n",
    "- \"sampled\" has the same 11 features, but only 160k samples\n",
    "- \"small\" also has 160k samples, but only the 5 features with lowest modalities count, and allow for fast experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:10.537799Z",
     "start_time": "2021-03-10T14:58:10.522197Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset= \"small_tb\" # fast expriments\n",
    "# dataset= \"medium_tb\" # fast expriments\n",
    "# dataset= \"sampled\" # fast expriments\n",
    "# dataset= \"small\" # fast expriments\n",
    "# dataset= \"sampled\" # Training a MRF may require 5h and 16Go data\n",
    "# dataset= \"full\"  # Training a MRF may require 32Go, and several days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2015, 2, 15)\n",
    "validation_split_date = datetime(2015, 3,3)\n",
    "end_date = datetime(2015, 3, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_df_from_parquet(\n",
    "            ss,\n",
    "            'viewfs://prod-am6/user/testfwk/datasets/criteo_1tb_parquet/date={year:04}-{month:02}-{day:02}',\n",
    "            None,\n",
    "            start_date,\n",
    "            validation_split_date\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = create_df_from_parquet(\n",
    "            ss,\n",
    "            'viewfs://prod-am6/user/testfwk/datasets/criteo_1tb_parquet/date={year:04}-{month:02}-{day:02}',\n",
    "            None,\n",
    "            validation_split_date,\n",
    "            end_date\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if 'feature' in c][0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Aggregated data\n",
    "\n",
    "- aggdata contains projections of number of displays and clicks along each pair of feature\n",
    "- may also add some noise to make it differential private\n",
    "- the goal is to learn a model predicting Proba( label | features) using *only* those aggdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = AggDataset(dataframe=train, features=features, label=label, maxNbModalities=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:14.075633Z",
     "start_time": "2021-03-10T14:58:14.061289Z"
    }
   },
   "outputs": [],
   "source": [
    "Validation = SparkMetricsComputer(label,\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:16.281216Z",
     "start_time": "2021-03-10T14:58:16.265527Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for of the privacy protecting noise.\n",
    "epsilon = None  # Set to None to get no noise.\n",
    "delta = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proposed MRF model\n",
    "- uses only aggregated data\n",
    "- almost retrieves logitic performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:09:05.630518Z",
     "start_time": "2021-03-10T15:09:04.461246Z"
    }
   },
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "nbSamples = 10000\n",
    "nbIter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(f\"viewfs://prod-am6/tmp/{getpass.getuser()}/load/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AggMRFModelParams(\n",
    "    exactComputation=False ,  ## Using Gibbs Sampling.  actualy exact=True is broken in latest code\n",
    "    clicksCfs = \"*&*\", ## crossfeatures used by P(Y|X) part of the model\n",
    "    displaysCfs=\"*&*\", ## crossfeatures used by P(X) part of the model. Here, all pairs + all single .\n",
    "    nbSamples = nbSamples, ## Nb Gibbs samples to estimate gradient\n",
    "    regulL2=1.0 ,  ## parmeter \"lambda_2\"\n",
    "    regulL2Click = regulL2,  ## parmeter \"lambda_1\"\n",
    "    sampleFromPY0 = True,\n",
    "    maxNbRowsperGibbsUpdate = 1,\n",
    ")\n",
    "rddMrf = AggMRFModel(aggdata, features, params, sparkSession = ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMrf.fit(1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"MRF\" ,  \"train\",  Validation.run(rddMrf, train) , \"valid\" , Validation.run(rddMrf,valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MTC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "aggregate_models_env",
   "language": "python",
   "name": "aggregate_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}