{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e017efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/home/a.gilotte/aggdata_public/.agg_model_venv/lib64/python3.6/site-packages/spnego/_ntlm_raw/crypto.py:22: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography.hazmat.backends import default_backend\n",
      "/mnt/nfs/home/a.gilotte/aggdata_public/.agg_model_venv/lib64/python3.6/site-packages/thx/tfpipeline/__init__.py:9: UserWarning: tensorflow & tf-yarn not found. You can install both with 'pip install tf-yarn'or add them to the requirements.txt of your project.\n",
      "  warnings.warn(str)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "from aggregated_models.myimports  import *\n",
    "import aggregated_models.myJupyterUtils as myJupyterUtils ## Remove stacktraces on Keyboardinterupt\n",
    "plt.style.use('classic')\n",
    "from aggregated_models.agg_mrf_model import *\n",
    "from aggregated_models.validation import * \n",
    "from aggregated_models.aggLogistic import AggLogistic\n",
    "\n",
    "# loading public \"criteo attribution dataset\"\n",
    "from aggregated_models.aggdataset import *\n",
    "from aggregated_models.FeatureEncodings import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d9031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aggregated_models import loaddata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05de5ed",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "#### banking\n",
    "more information about this data can be seen here: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "#### adult\n",
    "more information about this data can be seen here: https://archive.ics.uci.edu/ml/datasets/Adult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8318c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftrain, dftest, features = loaddata.load_banking_dataset()\n",
    "dftrain, dftest, features = loaddata.load_adult_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0bc872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio 0.2408095574460244 0.23622627602727106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workClass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Positive ratio\" ,   dftrain.label.sum() *1.0/len(dftrain) , dftest.label.sum() *1.0/len(dftest)  )\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e0a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   age             32561 non-null  int64\n",
      " 1   workClass       32561 non-null  int64\n",
      " 2   fnlwgt          32561 non-null  int64\n",
      " 3   education       32561 non-null  int64\n",
      " 4   education-num   32561 non-null  int64\n",
      " 5   marital-status  32561 non-null  int64\n",
      " 6   occupation      32561 non-null  int64\n",
      " 7   relationship    32561 non-null  int64\n",
      " 8   race            32561 non-null  int64\n",
      " 9   sex             32561 non-null  int64\n",
      " 10  capital-gain    32561 non-null  int64\n",
      " 11  capital-loss    32561 non-null  int64\n",
      " 12  hours-per-week  32561 non-null  int64\n",
      " 13  native-country  32561 non-null  int64\n",
      " 14  label           32561 non-null  int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "dftrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60136a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64982148",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = AggDataset.FromDF( dftrain , features, \"*&*\",  \"label\")\n",
    "Validation = MetricsComputer(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44a181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic(*&*), l2:10 train NLLH=0.4482, NMSE=0.4671   valid NLLH=0.4206, NMSE=0.4381  \n",
      "Logistic(*&*), l2:100 train NLLH=0.4188, NMSE=0.4399   valid NLLH=0.4072, NMSE=0.4273  \n",
      "Logistic(*&*), l2:1000 train NLLH=0.3592, NMSE=0.3857   valid NLLH=0.3565, NMSE=0.3827  \n"
     ]
    }
   ],
   "source": [
    "## Logistic model, with cross features\n",
    "regulL2s = [10,100,1000]\n",
    "for regulL2 in regulL2s:\n",
    "    logisticCfs = AggLogistic(  aggdata , features, clicksCfs = \"*&*\" , rescaling=True, regulL2=regulL2 )\n",
    "    logisticCfs.fit( dftrain[features] , nbIter = 200 )\n",
    "    print( f\"Logistic(*&*), l2:{regulL2}\" ,  \"train\",  Validation.run(logisticCfs,dftrain) , \"valid\" , Validation.run(logisticCfs,dftest)   )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8abb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccdd63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic(*), l2:1 train NLLH=0.4179, NMSE=0.4372   valid NLLH=0.4111, NMSE=0.4302  \n",
      "Logistic(*), l2:10 train NLLH=0.4098, NMSE=0.4301   valid NLLH=0.4048, NMSE=0.4248  \n",
      "Logistic(*), l2:100 train NLLH=0.3710, NMSE=0.3963   valid NLLH=0.3690, NMSE=0.3941  \n"
     ]
    }
   ],
   "source": [
    "## Logistic model, no cross features\n",
    "regulL2s = [1,10,100]\n",
    "for regulL2 in regulL2s:\n",
    "    logisticCfs = AggLogistic(  aggdata , features, clicksCfs = \"*\" , rescaling=True, regulL2=regulL2 )\n",
    "    logisticCfs.fit( dftrain[features] , nbIter = 200 )\n",
    "    print( f\"Logistic(*), l2:{regulL2}\" ,  \"train\",  Validation.run(logisticCfs,dftrain) , \"valid\" , Validation.run(logisticCfs,dftest)   )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b915a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF lambda= 100 train NLLH=0.4270, NMSE=0.4477   valid NLLH=0.4125, NMSE=0.4319  \n",
      "MRF lambda= 10 train NLLH=0.4540, NMSE=0.4717   valid NLLH=0.4187, NMSE=0.4355  \n",
      "MRF lambda= 1000 train NLLH=0.3725, NMSE=0.3990   valid NLLH=0.3690, NMSE=0.3950  \n"
     ]
    }
   ],
   "source": [
    "## Random Markov Field\n",
    "regulL2s = [ 100, 10, 1000 ]\n",
    "for regulL2 in regulL2s:\n",
    "    nbSamples = 10_000\n",
    "    nbIter = 200\n",
    "    params = AggMRFModelParams(\n",
    "        features=features,\n",
    "        exactComputation=False ,\n",
    "        clicksCfs = \"*&*\",\n",
    "        displaysCfs=\"*&*\",\n",
    "        nbSamples = nbSamples,\n",
    "        regulL2=1.0,\n",
    "        regulL2Click = regulL2 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "    self.fit(nbIter, alpha=0.01)\n",
    "    print( f\"MRF lambda= {regulL2}\",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df921c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488c2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF, no cfs, lambda= 1 train NLLH=0.4173, NMSE=0.4369   valid NLLH=0.4105, NMSE=0.4298  \n",
      "MRF, no cfs, lambda= 10 train NLLH=0.4100, NMSE=0.4303   valid NLLH=0.4051, NMSE=0.4249  \n",
      "MRF, no cfs, lambda= 100 train NLLH=0.3721, NMSE=0.3971   valid NLLH=0.3701, NMSE=0.3950  \n"
     ]
    }
   ],
   "source": [
    "## Random Markov Field, No cross features on label model\n",
    "regulL2s = [ 1, 10, 100 ]\n",
    "for regulL2 in regulL2s:\n",
    "    nbSamples = 10_000\n",
    "    nbIter = 200\n",
    "    params = AggMRFModelParams(\n",
    "        features=features,\n",
    "        exactComputation=False ,\n",
    "        clicksCfs = \"*\",\n",
    "        displaysCfs=\"*&*\",\n",
    "        nbSamples = nbSamples,\n",
    "        regulL2=1.0,\n",
    "        regulL2Click = regulL2 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "    self.fit(nbIter)\n",
    "    print( f\"MRF, no cfs, lambda= {regulL2}\",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72a10af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB lambda= 1 train NLLH=0.1787, NMSE=0.2784   valid NLLH=0.1767, NMSE=0.2805  \n",
      "NB lambda= 10 train NLLH=0.1962, NMSE=0.2799   valid NLLH=0.1948, NMSE=0.2822  \n",
      "NB lambda= 100 train NLLH=0.2455, NMSE=0.2774   valid NLLH=0.2435, NMSE=0.2787  \n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "regulL2s = [ 1, 10, 100 ]\n",
    "for regulL2 in regulL2s:\n",
    "    nbSamples = 10_000\n",
    "    nbIter = 200\n",
    "    params = AggMRFModelParams(\n",
    "        features=features,\n",
    "        exactComputation=False ,\n",
    "        clicksCfs = \"*\",\n",
    "        displaysCfs=\"*\",\n",
    "        nbSamples = nbSamples,\n",
    "        regulL2=1.0,\n",
    "        regulL2Click = regulL2 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "    self.fit(nbIter)\n",
    "    print( f\"NB lambda= {regulL2}\",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489460e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "795d2a38",
   "metadata": {},
   "source": [
    "#### effect of regularizing mu and theta\n",
    "(table 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2053bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF lambda_mu:1 l_theta:1 train NLLH=0.4751, NMSE=0.4910   valid NLLH=0.4091, NMSE=0.4268  \n",
      "MRF lambda_mu:1 l_theta:4 train NLLH=0.4742, NMSE=0.4900   valid NLLH=0.4086, NMSE=0.4261  \n",
      "MRF lambda_mu:1 l_theta:16 train NLLH=0.4749, NMSE=0.4909   valid NLLH=0.4089, NMSE=0.4264  \n",
      "MRF lambda_mu:1 l_theta:64 train NLLH=0.4745, NMSE=0.4903   valid NLLH=0.4089, NMSE=0.4262  \n",
      "MRF lambda_mu:1 l_theta:128 train NLLH=0.4750, NMSE=0.4909   valid NLLH=0.4091, NMSE=0.4265  \n",
      "MRF lambda_mu:4 l_theta:1 train NLLH=0.4629, NMSE=0.4798   valid NLLH=0.4160, NMSE=0.4328  \n",
      "MRF lambda_mu:4 l_theta:4 train NLLH=0.4629, NMSE=0.4801   valid NLLH=0.4161, NMSE=0.4327  \n",
      "MRF lambda_mu:4 l_theta:16 train NLLH=0.4628, NMSE=0.4799   valid NLLH=0.4156, NMSE=0.4320  \n",
      "MRF lambda_mu:4 l_theta:64 train NLLH=0.4632, NMSE=0.4803   valid NLLH=0.4163, NMSE=0.4329  \n",
      "MRF lambda_mu:4 l_theta:128 train NLLH=0.4628, NMSE=0.4798   valid NLLH=0.4158, NMSE=0.4322  \n",
      "MRF lambda_mu:16 l_theta:1 train NLLH=0.4493, NMSE=0.4678   valid NLLH=0.4192, NMSE=0.4365  \n",
      "MRF lambda_mu:16 l_theta:4 train NLLH=0.4493, NMSE=0.4675   valid NLLH=0.4191, NMSE=0.4362  \n",
      "MRF lambda_mu:16 l_theta:16 train NLLH=0.4491, NMSE=0.4674   valid NLLH=0.4192, NMSE=0.4362  \n",
      "MRF lambda_mu:64 l_theta:1 train NLLH=0.4332, NMSE=0.4529   valid NLLH=0.4155, NMSE=0.4340  \n",
      "MRF lambda_mu:64 l_theta:4 train NLLH=0.4332, NMSE=0.4533   valid NLLH=0.4154, NMSE=0.4340  \n",
      "MRF lambda_mu:64 l_theta:16 train NLLH=0.4332, NMSE=0.4532   valid NLLH=0.4155, NMSE=0.4340  \n",
      "MRF lambda_mu:64 l_theta:64 train NLLH=0.4332, NMSE=0.4529   valid NLLH=0.4156, NMSE=0.4340  \n",
      "MRF lambda_mu:64 l_theta:128 train NLLH=0.4333, NMSE=0.4533   valid NLLH=0.4156, NMSE=0.4342  \n",
      "MRF lambda_mu:128 l_theta:1 train NLLH=0.4234, NMSE=0.4442   valid NLLH=0.4103, NMSE=0.4298  \n",
      "MRF lambda_mu:128 l_theta:4 train NLLH=0.4235, NMSE=0.4442   valid NLLH=0.4105, NMSE=0.4301  \n",
      "MRF lambda_mu:128 l_theta:16 train NLLH=0.4234, NMSE=0.4445   valid NLLH=0.4104, NMSE=0.4302  \n",
      "MRF lambda_mu:128 l_theta:64 train NLLH=0.4234, NMSE=0.4442   valid NLLH=0.4104, NMSE=0.4300  \n",
      "MRF lambda_mu:128 l_theta:128 train NLLH=0.4235, NMSE=0.4445   valid NLLH=0.4103, NMSE=0.4300  \n"
     ]
    }
   ],
   "source": [
    "regulL2s=[1,4,16,64,128]\n",
    "regulL2Clicks=[1,4,16,64,128]\n",
    "nbSamples=10_000\n",
    "nbIter = 200\n",
    "for regulL2 in regulL2s:\n",
    "    for regulL2Click in regulL2Clicks:\n",
    "            #try:\n",
    "            params = AggMRFModelParams(\n",
    "                features=features,\n",
    "                exactComputation=False ,\n",
    "                clicksCfs = \"*&*\",\n",
    "                displaysCfs=\"*&*\",\n",
    "                nbSamples = nbSamples,\n",
    "                regulL2=1.0,\n",
    "                regulL2Click = regulL2 )\n",
    "            self = AggMRFModel(aggdata, params)\n",
    "            self.fit(nbIter, alpha=0.01)\n",
    "            print( f\"MRF lambda_mu:{regulL2} l_theta:{regulL2Click}\",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )\n",
    "            #except: print(f\"error while computing rmf with {regulL2} {regulL2Click}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### increasing the number of Gibbs samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14421951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF nbSamples = 100 train NLLH=0.3978, NMSE=0.4137   valid NLLH=0.3853, NMSE=0.4009  \n",
      "MRF nbSamples = 200 train NLLH=0.4184, NMSE=0.4357   valid NLLH=0.4046, NMSE=0.4216  \n",
      "MRF nbSamples = 500 train NLLH=0.4250, NMSE=0.4440   valid NLLH=0.4108, NMSE=0.4285  \n",
      "MRF nbSamples = 1000 train NLLH=0.4273, NMSE=0.4466   valid NLLH=0.4129, NMSE=0.4311  \n",
      "MRF nbSamples = 2000 train NLLH=0.4276, NMSE=0.4475   valid NLLH=0.4132, NMSE=0.4319  \n",
      "MRF nbSamples = 5000 train NLLH=0.4271, NMSE=0.4478   valid NLLH=0.4127, NMSE=0.4321  \n",
      "MRF nbSamples = 10000 train NLLH=0.4271, NMSE=0.4478   valid NLLH=0.4124, NMSE=0.4318  \n",
      "MRF nbSamples = 50000 train NLLH=0.4273, NMSE=0.4478   valid NLLH=0.4125, NMSE=0.4318  \n",
      "MRF nbSamples = 100000 train NLLH=0.4272, NMSE=0.4479   valid NLLH=0.4125, NMSE=0.4318  \n"
     ]
    }
   ],
   "source": [
    "nbIter = 200\n",
    "regulL2 = 1\n",
    "regulL2Clicks = 100\n",
    "for nbSamples in [100, 200, 500, 1000,2000,5000,10_000, 20_000, 50_000,100_000]:\n",
    "            params = AggMRFModelParams(\n",
    "                features=features,\n",
    "                exactComputation=False ,\n",
    "                clicksCfs = \"*&*\",\n",
    "                displaysCfs=\"*&*\",\n",
    "                nbSamples = nbSamples,\n",
    "                regulL2=regulL2,\n",
    "                regulL2Click = regulL2Clicks )\n",
    "            self = AggMRFModel(aggdata, params)\n",
    "            self.fit(nbIter, alpha=0.01)\n",
    "            print( f\"MRF nbSamples = {nbSamples}\",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb187f",
   "metadata": {},
   "source": [
    "#### Gradient rescaling\n",
    "the model usually requires significantly less iterations to converge when using the \"gradient rescaling\".\n",
    "(Note: on banking dataset, the effect is actually quite limited. It is more notieceable on the \"adult\" dataset, and on the Criteo AdKdd challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec470e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF modifiedGradient: True iters:50  train NLLH=0.4001, NMSE=0.4155   valid NLLH=0.3919, NMSE=0.4081  \n",
      "MRF modifiedGradient: True iters:100  train NLLH=0.4195, NMSE=0.4385   valid NLLH=0.4075, NMSE=0.4257  \n",
      "MRF modifiedGradient: True iters:150  train NLLH=0.4248, NMSE=0.4451   valid NLLH=0.4110, NMSE=0.4302  \n",
      "MRF modifiedGradient: True iters:200  train NLLH=0.4272, NMSE=0.4479   valid NLLH=0.4125, NMSE=0.4318  \n",
      "MRF modifiedGradient: True iters:250  train NLLH=0.4287, NMSE=0.4496   valid NLLH=0.4133, NMSE=0.4326  \n",
      "MRF modifiedGradient: True iters:300  train NLLH=0.4297, NMSE=0.4505   valid NLLH=0.4138, NMSE=0.4332  \n",
      "MRF modifiedGradient: True iters:350  train NLLH=0.4304, NMSE=0.4513   valid NLLH=0.4143, NMSE=0.4336  \n",
      "MRF modifiedGradient: True iters:400  train NLLH=0.4309, NMSE=0.4518   valid NLLH=0.4146, NMSE=0.4338  \n",
      "MRF modifiedGradient: True iters:450  train NLLH=0.4313, NMSE=0.4522   valid NLLH=0.4148, NMSE=0.4341  \n",
      "MRF modifiedGradient: True iters:500  train NLLH=0.4316, NMSE=0.4524   valid NLLH=0.4151, NMSE=0.4343  \n",
      "MRF modifiedGradient: False iters:50  train NLLH=0.3675, NMSE=0.3827   valid NLLH=0.3596, NMSE=0.3740  \n",
      "MRF modifiedGradient: False iters:100  train NLLH=0.4102, NMSE=0.4299   valid NLLH=0.3987, NMSE=0.4168  \n",
      "MRF modifiedGradient: False iters:150  train NLLH=0.4224, NMSE=0.4432   valid NLLH=0.4089, NMSE=0.4282  \n",
      "MRF modifiedGradient: False iters:200  train NLLH=0.4265, NMSE=0.4476   valid NLLH=0.4119, NMSE=0.4315  \n",
      "MRF modifiedGradient: False iters:250  train NLLH=0.4284, NMSE=0.4495   valid NLLH=0.4132, NMSE=0.4329  \n",
      "MRF modifiedGradient: False iters:300  train NLLH=0.4295, NMSE=0.4505   valid NLLH=0.4139, NMSE=0.4334  \n",
      "MRF modifiedGradient: False iters:350  train NLLH=0.4304, NMSE=0.4514   valid NLLH=0.4145, NMSE=0.4339  \n",
      "MRF modifiedGradient: False iters:400  train NLLH=0.4310, NMSE=0.4519   valid NLLH=0.4149, NMSE=0.4343  \n",
      "MRF modifiedGradient: False iters:450  train NLLH=0.4314, NMSE=0.4523   valid NLLH=0.4152, NMSE=0.4345  \n",
      "MRF modifiedGradient: False iters:500  train NLLH=0.4317, NMSE=0.4526   valid NLLH=0.4154, NMSE=0.4347  \n"
     ]
    }
   ],
   "source": [
    "for modifiedGradient in [True, False]:\n",
    "    params = AggMRFModelParams(\n",
    "                features=features,\n",
    "                exactComputation=False ,\n",
    "                clicksCfs = \"*&*\",\n",
    "                displaysCfs=\"*&*\",\n",
    "                nbSamples = nbSamples,\n",
    "                regulL2=1.0,\n",
    "                modifiedGradient =modifiedGradient,\n",
    "                regulL2Click = 100 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "        \n",
    "    nbIterPerStep = 50\n",
    "    for i in range(0,10):\n",
    "        self.fit(nbIterPerStep, alpha=0.01)\n",
    "        totalIters = (i+1) * nbIterPerStep\n",
    "        print( f\"MRF modifiedGradient: {modifiedGradient} iters:{totalIters} \",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a51b290",
   "metadata": {},
   "source": [
    "#### increasing step size on mu produces a 'good' model faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ee0833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF with muStepSizeMultiplier. iters:50  train NLLH=0.4079, NMSE=0.4287   valid NLLH=0.3996, NMSE=0.4199  \n",
      "MRF with muStepSizeMultiplier. iters:100  train NLLH=0.4198, NMSE=0.4409   valid NLLH=0.4078, NMSE=0.4278  \n",
      "MRF with muStepSizeMultiplier. iters:150  train NLLH=0.4244, NMSE=0.4454   valid NLLH=0.4108, NMSE=0.4305  \n",
      "MRF with muStepSizeMultiplier. iters:200  train NLLH=0.4270, NMSE=0.4480   valid NLLH=0.4124, NMSE=0.4319  \n",
      "MRF with muStepSizeMultiplier. iters:250  train NLLH=0.4285, NMSE=0.4495   valid NLLH=0.4132, NMSE=0.4328  \n",
      "MRF with muStepSizeMultiplier. iters:300  train NLLH=0.4295, NMSE=0.4504   valid NLLH=0.4138, NMSE=0.4332  \n",
      "MRF with muStepSizeMultiplier. iters:350  train NLLH=0.4302, NMSE=0.4510   valid NLLH=0.4142, NMSE=0.4334  \n",
      "MRF with muStepSizeMultiplier. iters:400  train NLLH=0.4306, NMSE=0.4514   valid NLLH=0.4146, NMSE=0.4338  \n",
      "MRF with muStepSizeMultiplier. iters:450  train NLLH=0.4308, NMSE=0.4517   valid NLLH=0.4146, NMSE=0.4338  \n",
      "MRF with muStepSizeMultiplier. iters:500  train NLLH=0.4313, NMSE=0.4518   valid NLLH=0.4150, NMSE=0.4340  \n"
     ]
    }
   ],
   "source": [
    "    params = AggMRFModelParams(\n",
    "                features=features,\n",
    "                exactComputation=False ,\n",
    "                clicksCfs = \"*&*\",\n",
    "                displaysCfs=\"*&*\",\n",
    "                nbSamples = 10_000,\n",
    "                regulL2=1.0,\n",
    "                muStepSizeMultiplier = 5,\n",
    "                modifiedGradient = True,\n",
    "                regulL2Click = 100 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "        \n",
    "    nbIterPerStep = 50\n",
    "    for i in range(0,10):\n",
    "        self.fit(nbIterPerStep, alpha=0.01)\n",
    "        totalIters = (i+1) * nbIterPerStep\n",
    "        print( f\"MRF with muStepSizeMultiplier. iters:{totalIters} \",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76091f28",
   "metadata": {},
   "source": [
    "#### but increasing the step size on both mu and theta makes the model diverge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abb4c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRF with stepsize * 5. iters:50  train NLLH=0.3738, NMSE=0.3893   valid NLLH=0.3580, NMSE=0.3710  \n",
      "MRF with stepsize * 5. iters:100  train NLLH=0.3726, NMSE=0.3863   valid NLLH=0.3560, NMSE=0.3673  \n",
      "MRF with stepsize * 5. iters:150  train NLLH=0.3803, NMSE=0.3956   valid NLLH=0.3630, NMSE=0.3757  \n",
      "MRF with stepsize * 5. iters:200  train NLLH=0.3738, NMSE=0.3873   valid NLLH=0.3564, NMSE=0.3673  \n",
      "MRF with stepsize * 5. iters:250  train NLLH=0.3782, NMSE=0.3929   valid NLLH=0.3607, NMSE=0.3724  \n",
      "MRF with stepsize * 5. iters:300  train NLLH=0.3857, NMSE=0.4014   valid NLLH=0.3680, NMSE=0.3809  \n",
      "MRF with stepsize * 5. iters:350  train NLLH=0.3860, NMSE=0.4014   valid NLLH=0.3688, NMSE=0.3814  \n",
      "MRF with stepsize * 5. iters:400  train NLLH=0.3854, NMSE=0.4004   valid NLLH=0.3683, NMSE=0.3808  \n",
      "MRF with stepsize * 5. iters:450  train NLLH=0.3886, NMSE=0.4046   valid NLLH=0.3715, NMSE=0.3846  \n",
      "MRF with stepsize * 5. iters:500  train NLLH=0.3733, NMSE=0.3875   valid NLLH=0.3558, NMSE=0.3670  \n"
     ]
    }
   ],
   "source": [
    "    params = AggMRFModelParams(\n",
    "                features=features,\n",
    "                exactComputation=False ,\n",
    "                clicksCfs = \"*&*\",\n",
    "                displaysCfs=\"*&*\",\n",
    "                nbSamples = 10_000,\n",
    "                regulL2=1.0,\n",
    "                muStepSizeMultiplier = 1,\n",
    "                modifiedGradient = True,\n",
    "                regulL2Click = 100 )\n",
    "    self = AggMRFModel(aggdata, params)\n",
    "        \n",
    "    nbIterPerStep = 50\n",
    "    for i in range(0,10):\n",
    "        self.fit(nbIterPerStep, alpha=0.01 * 5)\n",
    "        totalIters = (i+1) * nbIterPerStep\n",
    "        print( f\"MRF with stepsize * 5. iters:{totalIters} \",  \"train\",   Validation.run(self,dftrain) , \"valid\" , Validation.run(self,dftest)   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b404a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3990f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggregated_models_env",
   "language": "python",
   "name": "aggregated_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
