{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.609479Z",
     "start_time": "2021-03-10T14:58:02.907483Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from agg_models.myimports  import *\n",
    "import agg_models.myJupyterUtils as myJupyterUtils ## Remove stacktraces on Keyboardinterupt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "# helpers to compute metrics\n",
    "from agg_models.validation import MetricsComputer,  LLH  \n",
    "\n",
    "# baselines\n",
    "from agg_models.basicmodels import LogisticModel, NaiveBayesModel, LogisticModelWithCF \n",
    "from agg_models.aggLogistic import AggLogistic\n",
    "\n",
    "# loading public \"criteo attribution dataset\"\n",
    "import agg_models.loaddata as loaddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.630044Z",
     "start_time": "2021-03-10T14:58:04.610705Z"
    }
   },
   "outputs": [],
   "source": [
    "# code to prepare the aggregated dataset\n",
    "from agg_models.featuremappings import AggDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.646507Z",
     "start_time": "2021-03-10T14:58:04.631250Z"
    }
   },
   "outputs": [],
   "source": [
    "## Most relevant code is there:\n",
    "from agg_models.agg_mrf_model import AggMRFModel, fastGibbsSample, fastGibbsSampleFromPY0\n",
    "import agg_models.agg_mrf_model\n",
    "# also in https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/baseaggmodel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/home/j.rioufougeras/aggdata/.venv/lib64/python3.6/site-packages/thx/tfpipeline/__init__.py:9: UserWarning: tensorflow & tf-yarn not found. You can install both with 'pip install tf-yarn'or add them to the requirements.txt of your project.\n",
      "  warnings.warn(str)\n"
     ]
    }
   ],
   "source": [
    "import thx.hadoop.hdfs_cache as hdfs\n",
    "from thx.hadoop.spark_config_builder import create_remote_spark_session, SparkSession\n",
    "import pyspark\n",
    "from pyspark.sql import functions as F\n",
    "from thx.datasources.parquet import create_df_from_parquet\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.188.91.19:31188\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3-criteo-1607362448</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test Spark parallelize</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4bcf2407f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = create_remote_spark_session('Test Spark parallelize', 10, 1, memory='4g', memoryOverhead='2g', driver_memory='16g', hadoop_file_systems=['viewfs://root', 'viewfs://prod-am6'])\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWC5yFQ-0BIB"
   },
   "source": [
    "## Download Data\n",
    "- downloading criteo-research-attribution-dataset\n",
    "- from url http://go.criteo.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:07.104991Z",
     "start_time": "2021-03-10T14:58:07.086941Z"
    }
   },
   "outputs": [],
   "source": [
    "#loaddata.download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "3 versions of the dataset are used for experiments: \"small\" , \"sampled\" and \"full\"\n",
    "- \"full\" has 11 features with about 16M samples\n",
    "- \"sampled\" has the same 11 features, but only 160k samples\n",
    "- \"small\" also has 160k samples, but only the 5 features with lowest modalities count, and allow for fast experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:10.537799Z",
     "start_time": "2021-03-10T14:58:10.522197Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset= \"small_tb\" # fast expriments\n",
    "# dataset= \"medium_tb\" # fast expriments\n",
    "dataset= \"small\" # fast expriments\n",
    "# dataset= \"small\" # fast expriments\n",
    "# dataset= \"sampled\" # Training a MRF may require 5h and 16Go data\n",
    "# dataset= \"full\"  # Training a MRF may require 32Go, and several days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.645407Z",
     "start_time": "2021-03-10T14:58:10.842990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling ratio :0.01\n"
     ]
    }
   ],
   "source": [
    "train, valid, features, label = loaddata.getDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.665499Z",
     "start_time": "2021-03-10T14:58:13.646870Z"
    }
   },
   "outputs": [],
   "source": [
    "fids = [-60029,-60036,-60040,-60042,-60049,-160020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.681098Z",
     "start_time": "2021-03-10T14:58:13.666726Z"
    }
   },
   "outputs": [],
   "source": [
    "crosses = [ f\"{f}&{g}\" for i,f in enumerate(fids) for j,g in enumerate(fids) if i > j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.757565Z",
     "start_time": "2021-03-10T14:58:13.741176Z"
    }
   },
   "outputs": [],
   "source": [
    "len(crosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.912023Z",
     "start_time": "2021-03-10T14:58:13.896974Z"
    }
   },
   "outputs": [],
   "source": [
    "'|'.join(crosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:14.075633Z",
     "start_time": "2021-03-10T14:58:14.061289Z"
    }
   },
   "outputs": [],
   "source": [
    "Validation = MetricsComputer(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:14.232939Z",
     "start_time": "2021-03-10T14:58:14.216582Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:14.850248Z",
     "start_time": "2021-03-10T14:58:14.369006Z"
    }
   },
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    nbModalities = len(set(train[f].values))\n",
    "    print( f\"feature {f} has {nbModalities} distinct modalities\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Aggregated data\n",
    "\n",
    "- aggdata contains projections of number of displays and clicks along each pair of feature\n",
    "- may also add some noise to make it differential private\n",
    "- the goal is to learn a model predicting Proba( label | features) using *only* those aggdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:16.281216Z",
     "start_time": "2021-03-10T14:58:16.265527Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for of the privacy protecting noise.\n",
    "epsilon = None  # Set to None to get no noise.\n",
    "delta = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.075298Z",
     "start_time": "2021-03-10T14:58:16.477135Z"
    }
   },
   "outputs": [],
   "source": [
    "aggdata = AggDataset( features, \"*&*\", train , label, epsilon, delta )\n",
    "\n",
    "#https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/featuremappings.py#L205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.096088Z",
     "start_time": "2021-03-10T14:58:35.076835Z"
    }
   },
   "outputs": [],
   "source": [
    "print( f\" Label: {aggdata.label}\")\n",
    "print( f\" Nb Queries: {len(aggdata.aggDisplays)}\")\n",
    "print( f\" Noise distribution: {aggdata.noiseDistribution}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.151323Z",
     "start_time": "2021-03-10T14:58:35.097366Z"
    }
   },
   "outputs": [],
   "source": [
    "# aggdata may be viewed as a dictionary queryname -> dataframe\n",
    "aggdata_datframe_dico = aggdata.toDFs()\n",
    "queries = [x for x in aggdata_datframe_dico.keys()]\n",
    "print( f\"list of queries {queries}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.176277Z",
     "start_time": "2021-03-10T14:58:35.152487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe for the query  \" select 'cat1', 'cat8' , count, sum(label) group by 'cat1', 'cat8' \"\n",
    "aggdata_datframe_dico[queries[-3]].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.191234Z",
     "start_time": "2021-03-10T14:58:35.177237Z"
    }
   },
   "outputs": [],
   "source": [
    "aggdata.aggDisplays\n",
    "\n",
    "# Dictionary of projections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-10T15:54:26.912Z"
    }
   },
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "logisticCfs = LogisticModelWithCF(label , features, \"*&*\"  , train ,\n",
    "                                      hashspace=2**22 , lambdaL2 = regulL2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-10T15:54:26.912Z"
    }
   },
   "outputs": [],
   "source": [
    "# logisticCfs.fit( train )\n",
    "# print( f\"Logistic(*&*), l2:{regulL2}\" ,  \"train\",  Validation.run(logisticCfs,train) , \"valid\" , Validation.run(logisticCfs,valid)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### logistic Regression from aggregated clicks and full display data (quadratic kernell)\n",
    " - same performances as \"standard\" logistic regression\n",
    " - but still using full display data, so not really usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:38:45.762551Z",
     "start_time": "2021-03-10T15:30:58.183620Z"
    }
   },
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "logisticCfs = AggLogistic(  aggdata , features, clicksCfs = \"*&*\" , regulL2=regulL2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:38:45.762551Z",
     "start_time": "2021-03-10T15:30:58.183620Z"
    }
   },
   "outputs": [],
   "source": [
    "# logisticCfs.fit( train[features] , nbIter = 200 )\n",
    "# print( f\"Logistic(*&*), l2:{regulL2}\" ,  \"train\",  Validation.run(logisticCfs,train) , \"valid\" , Validation.run(logisticCfs,valid)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proposed MRF model\n",
    "- uses only aggregated data\n",
    "- almost retrieves logitic performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:09:05.630518Z",
     "start_time": "2021-03-10T15:09:04.461246Z"
    }
   },
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "nbSamples = 3000\n",
    "nbIter = 200\n",
    "\n",
    "self = AggMRFModel( aggdata,\n",
    "                    features , \n",
    "                    exactComputation=False ,  ## Using Gibbs Sampling.  actualy exact=True is broken in latest code\n",
    "                    clicksCfs = \"*&*\", ## crossfeatures used by P(Y|X) part of the model\n",
    "                    displaysCfs=\"*&*\", ## crossfeatures used by P(X) part of the model. Here, all pairs + all single .\n",
    "                    nbSamples = nbSamples, ## Nb Gibbs samples to estimate gradient\n",
    "                    regulL2=1.0 ,  ## parmeter \"lambda_2\"\n",
    "                    regulL2Click = regulL2,  ## parmeter \"lambda_1\" \n",
    "                    sampleFromPY0 = True,\n",
    "                    maxNbRowsperGibbsUpdate = 300,\n",
    "                    sparkSession = ss\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:29:58.173298Z",
     "start_time": "2021-03-10T15:09:13.357140Z"
    }
   },
   "outputs": [],
   "source": [
    "self.fit(nbIter)\n",
    "print( f\"MRF lambda1= {regulL2}\",  \"train\",   Validation.run(self,train) , \"valid\" , Validation.run(self,valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.samples.use_spark_rdd = True\n",
    "gRdd = self.computeGradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gRdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samples = np.vstack(self.samples.samplesRdd.map(lambda t: t[0]).collect()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.samples.data = final_samples\n",
    "self.computedotprods(self.samples)\n",
    "self.samples.computeProbaSamples(self.muIntercept, self.lambdaIntercept)\n",
    "self.samples.setweights()\n",
    "self.samples.applyreweighting(self.muIntercept, self.lambdaIntercept)\n",
    "self.samples.use_spark_rdd = False\n",
    "g = self.computeGradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "nbSamples = 10000\n",
    "nbIter = 50\n",
    "\n",
    "self = AggMRFModel( aggdata,\n",
    "                    features , \n",
    "                    exactComputation=False ,  ## Using Gibbs Sampling.  actualy exact=True is broken in latest code\n",
    "                    clicksCfs = \"*&*\", ## crossfeatures used by P(Y|X) part of the model\n",
    "                    displaysCfs=\"*&*\", ## crossfeatures used by P(X) part of the model. Here, all pairs + all single .\n",
    "                    nbSamples = nbSamples, ## Nb Gibbs samples to estimate gradient\n",
    "                    regulL2=1.0 ,  ## parmeter \"lambda_2\"\n",
    "                    regulL2Click = regulL2,  ## parmeter \"lambda_1\" \n",
    "                    sampleFromPY0 = True,\n",
    "                    maxNbRowsperGibbsUpdate = 300\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.fit(nbIter)\n",
    "print( f\"MRF lambda1= {regulL2}\",  \"train\",   Validation.run(self,train) , \"valid\" , Validation.run(self,valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:41.735854Z",
     "start_time": "2021-02-18T18:52:41.708511Z"
    }
   },
   "outputs": [],
   "source": [
    "# all parameters mu and theta concatenated in a  single vector\n",
    "self.parameters\n",
    "\n",
    "# This vector is the concatenation of parameters for associated to each projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNbRows = 100\n",
    "rows = self.samples.data.transpose()\n",
    "starts = np.arange(0,  len(rows) , maxNbRows)\n",
    "slices =[ (rows[start:start+maxNbRows]) for start in starts  ]\n",
    "rdd = ss.sparkContext.parallelize(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = ss.sparkContext.parallelize(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T19:40:06.020462Z",
     "start_time": "2021-02-15T19:40:05.992635Z"
    }
   },
   "outputs": [],
   "source": [
    "def RunRddGibbsSampler(self, rdd, nbsteps=1):\n",
    "        exportedDisplayWeights, exportedClickWeights, modalitiesByVarId, parameters = self.exportWeightsAll()\n",
    "        \n",
    "        def myfun_sampling_from_p_y0(s):\n",
    "            s  = fastGibbsSampleFromPY0(exportedDisplayWeights, modalitiesByVarId, parameters,\n",
    "                                 s,nbsteps )\n",
    "            return s\n",
    "                \n",
    "        return rdd.map(myfun_sampling_from_p_y0).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = RunRddGibbsSampler(self, rdd, nbsteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expdotproducts(self, rdd):\n",
    "\n",
    "    def expdotproducts(x):\n",
    "        t_x = x.transpose()\n",
    "        mus = np.zeros( x.shape[0] )\n",
    "        lambdas = np.zeros( x.shape[0] )\n",
    "        for w in self.displayWeights.values():\n",
    "            mus  += self.parameters[ w.feature.Values_(t_x) + w.offset ]\n",
    "        for w in self.clickWeights.values():\n",
    "            lambdas  += self.parameters[ w.feature.Values_(t_x) + w.offset ]\n",
    "        mus = np.exp(mus + self.muIntercept)\n",
    "        return x, mus,  mus*np.exp(lambdas + self.lambdaIntercept)\n",
    "    \n",
    "    return rdd.map(expdotproducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mu_lambdas = compute_expdotproducts(self, rdd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def compute_pdisplays(self, xmulambdas):\n",
    "    count = self.samples.Size\n",
    "    n = np.exp( self.muIntercept )\n",
    "    # x, expmu, explambda\n",
    "    z0_on_z = count / xmulambdas.map(lambda mula: 1+mula[2]/mula[1]).reduce(add)\n",
    "    enoclick = z0_on_z * (1+np.exp(self.lambdaIntercept)) * n /  count\n",
    "    def _computePDisplays(tuple_x_mu_lambda):\n",
    "        # x, expmu, explambda\n",
    "        eclick   = enoclick * tuple_x_mu_lambda[2] / tuple_x_mu_lambda[1]\n",
    "        return tuple_x_mu_lambda[0], enoclick, eclick\n",
    "    \n",
    "    return xmulambdas.map(_computePDisplays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enoclick_eclick = compute_pdisplays(self, x_mu_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionsVectorRdd(self , x_enoclick_eclick):  \n",
    "    \n",
    "    def computePredictions(tuple_x_enoclick_eclick):\n",
    "        p = self.parameters * 0\n",
    "        t_x = tuple_x_enoclick_eclick[0].transpose()\n",
    "        enoclick = tuple_x_enoclick_eclick[1]\n",
    "        eclick = tuple_x_enoclick_eclick[2]\n",
    "        for w in self.displayWeights.values():\n",
    "            p[w.indices] = w.feature.Project_(t_x, enoclick+eclick ) # Correct for grads\n",
    "        for w in self.clickWeights.values():\n",
    "            p[w.indices] = w.feature.Project_(t_x, eclick )        \n",
    "        return p\n",
    "\n",
    "    return x_enoclick_eclick.map(computePredictions).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = getPredictionsVector(self, x_enoclick_eclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(200):\n",
    "    rdd = RunRddGibbsSampler(self, rdd, nbsteps=1)\n",
    "    x_mu_lambdas = RunRddDotProduct(self,  rdd, self.displayWeights, self.muIntercept, self.clickWeights, self.lambdaIntercept)\n",
    "    x_enoclick_eclick = computePDisplays(self, x_mu_lambdas)\n",
    "    prediction = getPredictionsVector(self, x_enoclick_eclick)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(self.samples.Eclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:43.063475Z",
     "start_time": "2021-02-18T18:52:43.044297Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of features and crossfeatures for mu\n",
    "self.displayWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:43.804712Z",
     "start_time": "2021-02-18T18:52:43.786421Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of features and cfs for theta\n",
    "self.clickWeights\n",
    "# class WeightsSet : https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/baseaggmodel.py#L8\n",
    "\n",
    "## In parameter vector, indices from 3719 to 3729 are the parameters \"theta\" \n",
    "##   associated to values of the single feature \"cat1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:44.585384Z",
     "start_time": "2021-02-18T18:52:44.567790Z"
    }
   },
   "outputs": [],
   "source": [
    "# there are also two 'intercept' parameters:\n",
    "self.muIntercept, self.lambdaIntercept\n",
    "#  ...  thus P(Y = 1 |X =x) = sigmoid( K(x) . self.parameters[someOffset:] +  self.lambdaIntercept )\n",
    "\n",
    "#  todo:  remane self.lambdaIntercept to self.thetaIntercept to get coherent notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:45.345504Z",
     "start_time": "2021-02-18T18:52:45.328800Z"
    }
   },
   "outputs": [],
   "source": [
    "## samples of \"X\"\n",
    "\n",
    "self.samples.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:46.190688Z",
     "start_time": "2021-02-18T18:52:46.165986Z"
    }
   },
   "outputs": [],
   "source": [
    "## Computing dotproducts between K(x) and mu or theta:\n",
    "\n",
    "## https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/baseaggmodel.py#L62\n",
    "\n",
    "mus    = self.dotproducts( self.displayWeights, self.samples.data ) + self.muIntercept\n",
    "mus\n",
    "\n",
    "## https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/agg_mrf_model.py#L145\n",
    "\n",
    "## note: I just added some comments in the code, translating all the line numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:48.815691Z",
     "start_time": "2021-02-18T18:52:48.796343Z"
    }
   },
   "outputs": [],
   "source": [
    "d = self.Data\n",
    "d\n",
    "#  vector with  the counts of click or display  from aggregated data.\n",
    "# Same indexing as self.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:49.437250Z",
     "start_time": "2021-02-18T18:52:49.409260Z"
    }
   },
   "outputs": [],
   "source": [
    "p = self.getPredictionsVector( self.samples )\n",
    "p\n",
    "# expected counts according to the model, computed by MC on the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:50.022246Z",
     "start_time": "2021-02-18T18:52:50.002699Z"
    }
   },
   "outputs": [],
   "source": [
    "## https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/agg_mrf_model.py#L187\n",
    "w = self.displayWeights[\"integer_feature_10\"]\n",
    "w.feature.Project_(  self.samples.data  , self.samples.pdisplays ) # Correct for grads\n",
    "\n",
    "# a bit uselessly complicated :  self.samples.pdisplays  is constant\n",
    "# This allows having samples with different 'weights', for example one sample for each possible modality of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T13:52:56.706084Z",
     "start_time": "2021-02-16T13:52:56.677076Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:51.522871Z",
     "start_time": "2021-02-18T18:52:51.394959Z"
    }
   },
   "outputs": [],
   "source": [
    "# After fiting the model,  \"data\" and \"prediction\" should be equal\n",
    "plt.plot( d,p, \"x\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T18:52:52.545660Z",
     "start_time": "2021-02-18T18:52:52.416385Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... up to the noise of the sampling / convergence of optimizer\n",
    "plt.plot( np.log (1+d), np.log( 1+p), \"x\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MTC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "agg_models",
   "language": "python",
   "name": "agg_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
