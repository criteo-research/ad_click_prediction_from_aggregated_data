{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.609479Z",
     "start_time": "2021-03-10T14:58:02.907483Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from aggregated_models.myimports  import *\n",
    "# import aggregated_models.myJupyterUtils as myJupyterUtils ## Remove stacktraces on Keyboardinterupt\n",
    "plt.style.use('ggplot')\n",
    "import getpass\n",
    "\n",
    "# helpers to compute metrics\n",
    "from aggregated_models.validation import MetricsComputer\n",
    "\n",
    "from aggregated_models.validation import SparkMetricsComputer\n",
    "\n",
    "# loading public \"criteo attribution dataset\"\n",
    "import aggregated_models.loaddata as loaddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.630044Z",
     "start_time": "2021-03-10T14:58:04.610705Z"
    }
   },
   "outputs": [],
   "source": [
    "# code to prepare the aggregated dataset\n",
    "from aggregated_models.aggdataset import AggDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:04.646507Z",
     "start_time": "2021-03-10T14:58:04.631250Z"
    }
   },
   "outputs": [],
   "source": [
    "## Most relevant code is there:\n",
    "from aggregated_models.agg_mrf_model import AggMRFModel, AggMRFModelParams\n",
    "# also in https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/baseaggmodel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thx.hadoop.spark_config_builder import create_remote_spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = create_remote_spark_session('Test Spark parallelize', 20, 1, memory='4g', memoryOverhead='2g', driver_memory='12g', hadoop_file_systems=['viewfs://root', 'viewfs://prod-am6'])\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWC5yFQ-0BIB"
   },
   "source": [
    "## Download Data\n",
    "- downloading criteo-research-attribution-dataset\n",
    "- from url http://go.criteo.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:07.104991Z",
     "start_time": "2021-03-10T14:58:07.086941Z"
    }
   },
   "outputs": [],
   "source": [
    "#loaddata.download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "3 versions of the dataset are used for experiments: \"small\" , \"sampled\" and \"full\"\n",
    "- \"full\" has 11 features with about 16M samples\n",
    "- \"sampled\" has the same 11 features, but only 160k samples\n",
    "- \"small\" also has 160k samples, but only the 5 features with lowest modalities count, and allow for fast experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:10.537799Z",
     "start_time": "2021-03-10T14:58:10.522197Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset= \"small_tb\" # fast expriments\n",
    "# dataset= \"medium_tb\" # fast expriments\n",
    "# dataset= \"sampled\" # fast expriments\n",
    "dataset= \"small\" # fast expriments\n",
    "# dataset= \"sampled\" # Training a MRF may require 5h and 16Go data\n",
    "# dataset= \"full\"  # Training a MRF may require 32Go, and several days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:13.645407Z",
     "start_time": "2021-03-10T14:58:10.842990Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid, features, label = loaddata.getDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ss.createDataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = ss.createDataFrame(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation = MetricsComputer(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:14.075633Z",
     "start_time": "2021-03-10T14:58:14.061289Z"
    }
   },
   "outputs": [],
   "source": [
    "SparkValidation = SparkMetricsComputer(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Aggregated data\n",
    "\n",
    "- aggdata contains projections of number of displays and clicks along each pair of feature\n",
    "- may also add some noise to make it differential private\n",
    "- the goal is to learn a model predicting Proba( label | features) using *only* those aggdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:16.281216Z",
     "start_time": "2021-03-10T14:58:16.265527Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for of the privacy protecting noise.\n",
    "epsilon = None  # Set to None to get no noise.\n",
    "delta = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdata = AggDataset( features=features, dataframe=train, label=label, maxNbModalities=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T14:58:35.075298Z",
     "start_time": "2021-03-10T14:58:16.477135Z"
    }
   },
   "outputs": [],
   "source": [
    "sparkdata = AggDatasetSpark( features=features, train=df_train, label=label, maxNbModalities=10000)\n",
    "\n",
    "#https://gitlab.criteois.com/a.gilotte/aggdata/-/blob/master/src/featuremappings.py#L205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proposed MRF model\n",
    "- uses only aggregated data\n",
    "- almost retrieves logitic performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T15:09:05.630518Z",
     "start_time": "2021-03-10T15:09:04.461246Z"
    }
   },
   "outputs": [],
   "source": [
    "regulL2 = 16\n",
    "nbSamples = 10000\n",
    "nbIter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AggMRFModelParams(\n",
    "    exactComputation=False ,  ## Using Gibbs Sampling.  actualy exact=True is broken in latest code\n",
    "    clicksCfs = \"*&*\", ## crossfeatures used by P(Y|X) part of the model\n",
    "    displaysCfs=\"*&*\", ## crossfeatures used by P(X) part of the model. Here, all pairs + all single .\n",
    "    nbSamples = nbSamples, ## Nb Gibbs samples to estimate gradient\n",
    "    regulL2=1.0 ,  ## parmeter \"lambda_2\"\n",
    "    regulL2Click = regulL2,  ## parmeter \"lambda_1\"\n",
    "    sampleFromPY0 = True,\n",
    ")\n",
    "memMrf = AggMRFModel(aggdata, features, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memMrf.fit(nbIter, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"MRF\" ,  \"train\",  Validation.run(memMrf,train) , \"valid\" , Validation.run(memMrf,valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memMrf.aggdata = sparkdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"MRF\" ,  \"train\",  SparkValidation.run(memMrf, df_train) , \"valid\" , SparkValidation.run(memMrf, df_valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(f\"viewfs://prod-am6/tmp/{getpass.getuser()}/load/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AggMRFModelParams(\n",
    "    exactComputation=False ,  ## Using Gibbs Sampling.  actualy exact=True is broken in latest code\n",
    "    clicksCfs = \"*&*\", ## crossfeatures used by P(Y|X) part of the model\n",
    "    displaysCfs=\"*&*\", ## crossfeatures used by P(X) part of the model. Here, all pairs + all single .\n",
    "    nbSamples = nbSamples, ## Nb Gibbs samples to estimate gradient\n",
    "    regulL2=1.0 ,  ## parmeter \"lambda_2\"\n",
    "    regulL2Click = regulL2,  ## parmeter \"lambda_1\"\n",
    "    sampleFromPY0 = True,\n",
    ")\n",
    "rddMrf = AggMRFModel(sparkdata, features, params, sparkSession = ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMrf.fit(nbIter, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"MRF\" ,  \"train\",  SparkValidation.run(rddMrf, df_train) , \"valid\" , SparkValidation.run(rddMrf, df_valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMrf.aggdata = aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"MRF\" ,  \"train\",  Validation.run(rddMrf, train) , \"valid\" , Validation.run(rddMrf, valid)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MTC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "aggregate_models_env",
   "language": "python",
   "name": "aggregate_models_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}